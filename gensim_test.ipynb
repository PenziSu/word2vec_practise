{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徵提取 (Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料集: [['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey'], ['fish', 'cat', 'dog']]\n",
      "\n",
      "[ 1.6002206e-03 -1.2094593e-03 -1.4216034e-03  4.0658592e-04\n",
      " -1.3757666e-03 -1.8757244e-03  1.0476712e-03  2.7792191e-03\n",
      " -2.1818881e-03 -3.0379808e-03 -1.1105891e-03  2.5090785e-03\n",
      " -3.2296721e-03  3.1994260e-03 -1.3941566e-04  7.6826813e-04\n",
      " -6.1655365e-04 -1.9207029e-03  1.0335651e-03  2.0650295e-03\n",
      " -2.3509685e-03 -3.9110542e-04  5.1980693e-04  1.4163239e-03\n",
      "  2.3804498e-03 -1.1822319e-03  2.4251295e-03 -1.8569903e-03\n",
      " -7.3160848e-04  3.0282540e-03  1.7941077e-03 -2.8283524e-03\n",
      " -5.5188139e-04 -2.9460737e-03 -5.4729305e-04  1.8852059e-03\n",
      " -2.4727657e-03  1.8366897e-03  2.0300196e-03 -1.2568263e-03\n",
      " -3.2186047e-03 -8.3960575e-04 -8.5100770e-04  1.2528455e-03\n",
      "  2.9735616e-03  6.6530070e-04 -7.0384541e-04  9.8985550e-04\n",
      " -2.2679062e-03 -4.3111682e-04 -4.9441139e-04  3.2016218e-03\n",
      " -1.9365211e-03 -2.3467473e-03  7.8704953e-04  8.7825657e-04\n",
      " -2.3819907e-03 -1.9592512e-03 -3.9434075e-04 -1.1009414e-03\n",
      " -2.9919101e-03 -1.3498397e-03 -9.8858471e-04  2.1675550e-03\n",
      "  3.2463233e-04  5.3293706e-04  9.2779796e-05 -1.1280461e-03\n",
      "  1.0341231e-03  2.3722171e-04  1.9942792e-03 -2.5840639e-04\n",
      " -2.9670887e-03  2.9425183e-04  3.3079397e-03 -1.7497241e-03\n",
      " -1.7388221e-03 -8.3958346e-04  2.8611496e-03 -2.7721486e-04\n",
      "  3.1394558e-03 -2.7787033e-03  3.0056806e-03 -3.2377073e-03\n",
      "  3.0665200e-03  6.2423787e-04  8.8681618e-04 -1.9528671e-03\n",
      "  2.8130619e-03  2.0145436e-03 -1.8290461e-03 -3.1662730e-03\n",
      "  2.3228005e-03 -1.8453101e-03 -3.1071075e-03  8.6578570e-04\n",
      " -1.6593368e-03 -2.4533502e-03  3.2435195e-03 -5.2860816e-04\n",
      " -5.0367118e-04 -1.3448346e-03 -1.4662842e-03 -1.5431285e-03\n",
      " -1.8652380e-03 -1.7672678e-03 -2.6741007e-03  3.1729483e-03\n",
      "  2.1330218e-03 -1.2022313e-03  8.2614738e-04 -2.5474981e-03\n",
      "  2.5077006e-03  2.7682451e-03  2.6314339e-04 -2.2776634e-03\n",
      " -9.8590925e-04  1.5779897e-03 -9.7979465e-04  1.0588245e-03\n",
      "  3.1362385e-03  1.4510354e-03 -1.7151599e-03  1.8223643e-03\n",
      " -9.5973053e-04 -2.1313136e-03  2.3359337e-03 -3.0846444e-03\n",
      " -3.7688573e-04 -4.6178023e-04 -2.8053157e-03 -3.6746662e-04\n",
      "  1.8657525e-03 -1.7558840e-03 -2.3420453e-03  2.0667561e-03\n",
      " -1.1421465e-03 -2.6065186e-03  9.7790158e-05 -1.6600688e-05\n",
      "  2.5136357e-03  1.8976728e-04  2.6274864e-03 -3.2709274e-03\n",
      "  1.3444225e-03  2.0727033e-03  3.4314793e-04 -9.4547035e-04\n",
      "  3.4220496e-04 -2.7970711e-04 -2.7027563e-03 -2.2611574e-03\n",
      "  4.0005168e-04 -6.7262450e-04  3.1831395e-03 -3.1647563e-04\n",
      "  2.0395652e-03  6.8204600e-04  2.6998965e-03 -3.0968399e-03\n",
      "  7.9757650e-04 -4.8375249e-04  7.1833335e-04 -7.3266427e-05\n",
      " -2.2135437e-03  3.0168188e-03 -9.4779930e-04  6.3810468e-04\n",
      " -2.1472326e-03  1.2380728e-03  3.3319350e-03 -3.9875149e-04\n",
      "  2.1934060e-03 -4.1440329e-05  2.6427272e-03  3.2169768e-03\n",
      " -1.3042887e-04 -5.6611461e-04 -3.1738719e-03  3.2916244e-03\n",
      " -8.4432203e-04  7.2973053e-04 -5.6629541e-04  2.7757827e-03\n",
      "  2.7812591e-03  5.1229517e-04  9.6188864e-04  2.1446883e-03\n",
      "  7.4923359e-04  2.1481053e-03  4.8913560e-05 -7.6182367e-04\n",
      "  1.7690845e-03 -1.1384249e-03 -8.7187014e-04  2.9305764e-03\n",
      " -3.0515643e-03 -1.1378808e-03 -9.7470917e-04  1.8896433e-03\n",
      "  2.6478323e-03 -2.1505356e-03  1.9315104e-03 -7.2557530e-05\n",
      " -3.0106206e-03 -8.1422291e-04 -5.2811066e-04 -1.4936069e-03\n",
      " -2.6459375e-04 -1.7461447e-03  1.9801983e-03  3.1011268e-03\n",
      " -5.2922167e-04  1.1255809e-03 -2.4933854e-04 -2.3321073e-04\n",
      " -2.3368536e-03  4.8563481e-04  1.3008976e-03  2.3033575e-03\n",
      "  2.1796136e-03  1.1788678e-03  1.5538903e-03 -2.4773702e-03\n",
      " -4.6216647e-04 -1.9275475e-03  2.2670159e-03  2.6088811e-03\n",
      " -1.4246738e-03  3.8455249e-04  1.7031347e-03  6.0316164e-04\n",
      "  2.6197196e-04 -2.2467200e-03  3.2775598e-03 -2.4199008e-03\n",
      " -2.0112514e-03 -1.8886940e-03 -2.1159879e-03 -1.1636869e-03\n",
      " -3.1334318e-03  3.9271117e-04 -1.2500783e-03 -8.5042912e-04\n",
      "  1.9283135e-03  1.1834939e-03  6.0697278e-04 -4.5801679e-04\n",
      "  3.2924926e-03  9.5520023e-05  1.6718186e-03  3.0125834e-03\n",
      " -3.2555263e-03 -3.0517909e-03  3.3076091e-03  9.1226259e-04\n",
      " -6.2852702e-04  1.5746880e-03 -1.4384679e-03 -2.1325462e-03\n",
      " -2.7524689e-03  2.4033734e-03 -8.1645726e-04 -2.5143889e-03\n",
      " -1.9701286e-03  2.0585076e-03 -8.2656345e-04 -2.0485965e-03\n",
      " -5.3932704e-04 -4.9118401e-04 -1.0849480e-03 -6.9641270e-04\n",
      "  1.3685778e-03  4.8219998e-04 -1.1634473e-03  8.9745800e-04\n",
      "  1.7429809e-03 -3.0636035e-03 -2.5194457e-03  2.0987892e-03\n",
      " -2.9793684e-03  1.7607451e-04 -2.9979395e-03  2.7899428e-03\n",
      " -1.4311790e-03 -2.2068326e-03 -4.6125689e-04 -3.7122489e-04\n",
      "  2.5110086e-03  3.0365081e-03 -1.1692405e-04  8.9785934e-04\n",
      "  1.5790657e-03  4.7584774e-05 -1.9266673e-03 -1.9813975e-04\n",
      "  7.2765828e-04  2.7672378e-03 -1.1974418e-03 -3.2818485e-03]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "# 載入預訓練模型\n",
    "common_texts.append([\"fish\", \"cat\", \"dog\"])\n",
    "print(\"訓練資料集:\", common_texts)\n",
    "print()\n",
    "model = Word2Vec(common_texts, min_count=1, vector_size=300)\n",
    "\n",
    "def get_sentence_vector(sentence, model):\n",
    "  \"\"\"將句子轉換為向量表示.\"\"\"\n",
    "  vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "  if not vectors:\n",
    "    return None  # 或者返回一個預設的向量，例如零向量\n",
    "  return sum(vectors) / len(vectors)\n",
    "\n",
    "# 示例文本\n",
    "sentence = [\"human\"]\n",
    "vector = get_sentence_vector(sentence, model)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詞彙擴展 (Vocabulary Expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('graph', 0.09825022518634796), ('survey', 0.08705343306064606), ('interface', 0.0473613440990448)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "# 載入預訓練模型\n",
    "# model = Word2Vec(common_texts, min_count=1)\n",
    "\n",
    "# 尋找與 \"London\" 最相似的三個詞\n",
    "similar_words = model.wv.most_similar(\"dog\", topn=3)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息檢索 (Information Retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最相似的文件是：['human', 'interface', 'computer']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 載入預訓練模型 (這裡需要一個已載入的模型)\n",
    "# 例如: model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "\n",
    "documents = [\n",
    "    ['human', 'interface', 'computer'], \n",
    "    ['survey', 'user', 'computer', 'system', 'response', 'time'], \n",
    "    ['eps', 'user', 'interface', 'system'],\n",
    "]\n",
    "query = [\"interface\", \"response\"]\n",
    "\n",
    "# 建立文件向量 (簡化版，應使用更完善的方法)\n",
    "doc_vectors = [get_sentence_vector(doc, model) for doc in documents]\n",
    "\n",
    "# 計算查詢向量\n",
    "query_vector = get_sentence_vector(query, model)\n",
    "\n",
    "# 計算相似度 (此處假設 get_sentence_vector 函數已定義並能正常工作)\n",
    "if query_vector is not None:\n",
    "    similarities = [model.wv.cosine_similarities(query_vector, [vec]) for vec in doc_vectors]\n",
    "    # 找到最相似的文件\n",
    "    most_similar_doc_index = similarities.index(max(similarities))\n",
    "    print(f\"最相似的文件是：{documents[most_similar_doc_index]}\")\n",
    "else:\n",
    "    print(\"查詢向量無法計算，因為詞彙不在模型中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推薦系統 (Recommendation Systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "# 簡易的用戶行為數據\n",
    "user_history = {\n",
    "    \"user1\": [\"London\", \"Paris\", \"Berlin\"],\n",
    "    \"user2\": [\"Paris\", \"Rome\", \"Madrid\"],\n",
    "}\n",
    "\n",
    "# 建立一個簡單的模型\n",
    "model = Word2Vec(list(user_history.values()), min_count=1)\n",
    "\n",
    "# 獲取用戶1的歷史行為向量\n",
    "user1_vector = get_sentence_vector(user_history[\"user1\"], model)\n",
    "\n",
    "# 找到最相似的詞 (推薦)\n",
    "if user1_vector is not None:\n",
    "    recommendations = model.wv.most_similar(positive=[user1_vector], topn=2)\n",
    "    print(recommendations)\n",
    "else:\n",
    "    print(\"用戶向量無法計算。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可視化 (Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# 建立模型\n",
    "model = Word2Vec(common_texts, min_count=1)\n",
    "\n",
    "# 準備數據\n",
    "words = list(model.wv.index_to_key)\n",
    "vectors = [model.wv[word] for word in words]\n",
    "\n",
    "# 使用 t-SNE 降維\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "vectors_2d = tsne.fit_transform(vectors)\n",
    "\n",
    "# 繪圖\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i, word in enumerate(words):\n",
    "  plt.scatter(vectors_2d[i, 0], vectors_2d[i, 1])\n",
    "  plt.annotate(word, (vectors_2d[i, 0], vectors_2d[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "知識圖譜補全 (Knowledge Graph Completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定義實體和關係\n",
    "entities = {\"London\": 0, \"Paris\": 1, \"Berlin\": 2, \"UK\": 3, \"France\": 4, \"Germany\": 5}\n",
    "relations = {\"capital_of\": 0}\n",
    "\n",
    "# 簡化的知識圖譜 (三元組: 頭實體, 關係, 尾實體)\n",
    "triples = [\n",
    "    (entities[\"London\"], relations[\"capital_of\"], entities[\"UK\"]),\n",
    "    (entities[\"Paris\"], relations[\"capital_of\"], entities[\"France\"]),\n",
    "    (entities[\"Berlin\"], relations[\"capital_of\"], entities[\"Germany\"]),\n",
    "]\n",
    "\n",
    "# 初始化實體和關係的向量表示\n",
    "entity_dim = 2\n",
    "relation_dim = 2\n",
    "entity_embeddings = np.random.rand(len(entities), entity_dim)\n",
    "relation_embeddings = np.random.rand(len(relations), relation_dim)\n",
    "\n",
    "# 定義 TransE 模型的損失函數 (簡化版)\n",
    "def score_function(h, r, t):\n",
    "  return np.linalg.norm(h + r - t)\n",
    "\n",
    "# 訓練模型 (簡化版)\n",
    "learning_rate = 0.01\n",
    "for epoch in range(100):\n",
    "  for h, r, t in triples:\n",
    "    h_vec = entity_embeddings[h]\n",
    "    r_vec = relation_embeddings[r]\n",
    "    t_vec = entity_embeddings[t]\n",
    "\n",
    "    # 計算梯度 (簡化版)\n",
    "    grad_h = 2 * (h_vec + r_vec - t_vec)\n",
    "    grad_r = 2 * (h_vec + r_vec - t_vec)\n",
    "    grad_t = -2 * (h_vec + r_vec - t_vec)\n",
    "\n",
    "    # 更新向量\n",
    "    entity_embeddings[h] -= learning_rate * grad_h\n",
    "    relation_embeddings[r] -= learning_rate * grad_r\n",
    "    entity_embeddings[t] -= learning_rate * grad_t\n",
    "\n",
    "# 預測 London 的首都\n",
    "london_vec = entity_embeddings[entities[\"London\"]]\n",
    "capital_of_vec = relation_embeddings[relations[\"capital_of\"]]\n",
    "predicted_tail = london_vec + capital_of_vec\n",
    "\n",
    "# 找到最接近的實體\n",
    "distances = [np.linalg.norm(predicted_tail - entity_embeddings[i]) for i in range(len(entities))]\n",
    "predicted_entity_index = np.argmin(distances)\n",
    "\n",
    "# 輸出預測結果\n",
    "for entity, index in entities.items():\n",
    "  if index == predicted_entity_index:\n",
    "    print(f\"London 的首都可能是: {entity}\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
